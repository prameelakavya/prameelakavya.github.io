{
  "name": "Medical Named Entity Recognition in tweets",
  "tagline": "By kavya, aditi and udbhav",
  "body": "### Introduction:\r\nThis project aims at parsing named entities and recognizing and classifying medical data into the relevant categories, namely drugs, diseases, symptoms, side-effects, treatment, etc. Twitter data will be the input and based on previous medical data from databases and ontologies, relevant medical terms have to be parsed and classified (medical named entities are recognized and classified based on the category they belong to(ex: drug or a disease or cure etc...).)\r\n\r\n### Problem Statement:\r\nThe task of a Medical Name Entity Recognizer is to identify medical entities in text. Medical entities can be diseases, drugs, symptoms, etc. Previously, researchers in the field have used hand crafted features to identify medical entities in medical literature. In this work, we wish to extend medical entity recognition on tweets. We are expected to use NLP toolkits designed for processing tweets along with other medical ontologies (or databases) to exploit a lot of semantic features for this task.\r\n\r\n### Challenges we faced:\r\n* Tweets are very noisy and so much contextual.\r\n* All tweets containing the keyword 'asthma' are not about the disease 'asthma'.\r\n* Learning distributed representations for medical tweets.\r\n* Entity linking for exploiting semantic features from ontologies (UMLS, MetaMap).\r\n\r\n### Applications:\r\n* The results of analyzing such data can be used by pharma companies to boost their sales and also procure knowledge about sales of drugs manufactured by other companies pertaining to the same disease.\r\n* These results will also be beneficial in getting an estimate of the presence of any disease in a particular region and its prevalence.\r\n\r\n### DataSet:\r\n* We have a dataset of 1 year of tweets about 4 diseases and 32 drugs. \r\n* A team of domain experts has annotated about 2000 tweets with entities (around 20 types: diseases, drugs, symptoms) and relations (around 40 relation types: cures, causes, etc). \r\n\r\n### ToolKits we used:\r\n* CRF++\r\n* Metamap+\r\n* NLTK\r\n\r\n### Algorithm:\r\n**_The algorithm we used for classifying the medical text goes like this:_**\r\n* _Parsing and tokenizing tweets_\r\n* _Using training data labels to generate the feature files (for both 1-gram and 5-gram models)._\r\n* _Using the output feature file generated in step 2, along with the template file, we use crf_learn command to generate a model file (for both 1-gram and 5-gram)._\r\n* _We now generate the feature files for the testing data, excluding the labels._\r\n* _Using the output feature file generated in step 4, along with the template file, we use crf_test command to get the labels for the test data._\r\n* _We compare the predicted labels with the actual test data labels to get the percentage accuracy._\r\n\r\n**_Features Used:_**\r\n* _Word features_ : The word itself, two words before and three words after, along with their lemmas(its the root word of the current token).\r\n* _Morphosyntactic features_ : POS tags of the word itself, two words before and three words after.\r\n* _Semantic features_ : Semantic category of the word, provided by Metamap+.\r\n* _Other features_ : Next noun, previous verb, previous adjective, next verb.\r\n* _Orthographic features_ : The word contains -, +, &, etc.. is a number, letter, punctuation, etc.. is in upper case, capitalized, etc.. Prefixes of different length (from 1 to 4),Suffixes of different length (from 1 to 4).\r\n\r\n### Analysis from experiments:\r\nInitially we trained using only one feature for 1-gram thing which is just the token and its corresponding label and for 5-gram thing we just took the token, previous two words and next two words.\r\nBut later we thought of increasing the features and also the features that might effect the current words label, since as we have said before **tweets are more contextual**. The features used are mentioned above.\r\n* We used word features because of the language dependency of the current word on its neighbors.\r\n* We used POS tags to incorporate grammatic rules.\r\n* We used Semantic feature of each word to find how much is it related to the label.\r\n* We used orthographic features because medical terms have long biological names(length feature comes into picture) and similarly others.\r\n* We also used other features like nearest previous adjective , because adjectives give a way more insight into the disease or symptoms.\r\n\r\n### Accuracy:\r\n\r\n\r\n### Tags:\r\nInformation retrieval and extraction.\r\nMajor Project.\r\nMedical entity recognition.\r\nIIIT HYDERABAD.\r\nTweets.\r\nConditional random fields.\r\nFeature extraction.\r\n\r\nThe source code can be viewed at [GitHub Link](https://github.com/prameelakavya/prameelakavya.github.io)\r\nA video describing the procedure and results can be found at [youtube video link]()\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}